# Deadlock and Performance Fix

## Problem Analysis

Your scraper was stopping mid-execution due to:

### 1. **Over-Threading on Low-End Hardware** âš ï¸
- **Configuration**: 20 workers on 2-core/4-thread CPU
- **Impact**: Severe resource contention, thread starvation, and context switching overhead
- **Solution**: Reduced `MAX_WORKERS` from 20 to 4 to match your CPU capabilities

### 2. **Potential Deadlock in Rate Limit Handler** ğŸ”’
- **Problem**: `sleep_and_reset()` acquires lock, then makes network call via `notifier.send()`
- **Impact**: If Discord webhook is slow/blocked, all threads waiting for the lock will freeze
- **Solution**: Added `sleep_in_progress` flag and wrapped notifications in try-except

### 3. **Discord Webhook Timeout** â±ï¸
- **Problem**: 10-second timeout can block threads
- **Solution**: Reduced timeout to 5s and added specific timeout handling

## Changes Made

### âœ… 1. Reduced MAX_WORKERS (Line 93)
```python
MAX_WORKERS = 4  # Maximum concurrent workers (match CPU threads: 2core/4thread)
```
**Reason**: Prevents thread thrashing on your hardware

### âœ… 2. Added sleep_in_progress Flag (Line 174)
```python
self.sleep_in_progress = False  # Flag to ensure only one thread handles sleep
```
**Reason**: Prevents multiple threads from entering sleep logic simultaneously

### âœ… 3. Enhanced sleep_and_reset() Logic (Lines 283-337)
```python
with self.lock:
    if not self.global_sleep_mode or self.sleep_in_progress:
        return  # Another thread already handling it
    self.sleep_in_progress = True
    # ...

# Send notification with error handling (outside lock!)
try:
    notifier.send(...)
except Exception as e:
    logger.error(f"Failed to send sleep notification: {e}")
```
**Reason**: 
- Prevents deadlock by making network calls outside the lock
- Ensures only one thread handles sleep/reset
- Gracefully handles notification failures

### âœ… 4. Discord Timeout Reduction (Line 371)
```python
response = requests.post(self.webhook_url, json=payload, timeout=5)
# ...
except requests.exceptions.Timeout:
    logger.warning("Discord notification timed out (5s)")
```
**Reason**: Prevents long waits on slow/unavailable webhook

## Performance Recommendations

### For Your 2-Core/4-Thread System:
1. âœ… **4 workers** (current setting) - Optimal
2. âš ï¸ If still experiencing issues, try **2 workers** for more stability
3. âœ… Keep `REQUEST_DELAY = 0.05` to avoid rate limiting

### If You Have More Tokens Than Workers:
- The token borrowing system will automatically use available tokens
- Each worker will rotate through all available tokens efficiently

## Testing Recommendations

### 1. Monitor Resource Usage
```powershell
# Watch CPU/Memory in PowerShell
while ($true) { 
    Get-Process python | Select-Object CPU, WorkingSet, Threads
    Start-Sleep -Seconds 5 
}
```

### 2. Check Log for Deadlock Indicators
Look for patterns like:
- âŒ Workers stuck with no progress for >5 minutes
- âŒ "All tokens exhausted" without subsequent "Sleep period ended"
- âœ… "sleep_in_progress" preventing duplicate sleeps

### 3. Verify Thread Pool Behavior
```python
# The scraper will log:
"âœ“ All tokens reset, resuming scraping..."
```
If you see this, the fix is working!

## What to Expect Now

### âœ… Better Behavior:
- **No deadlocks**: Network calls won't block the lock
- **Stable threading**: 4 workers match your CPU capabilities
- **Graceful failures**: Discord failures won't crash the scraper
- **Single sleep handler**: Only one thread sleeps for rate limits

### ğŸ“Š Performance Expectations (2-core/4-thread):
- **Throughput**: ~200-400 repos/hour (depending on API responses)
- **CPU usage**: 50-80% (healthy range)
- **Memory**: Stable, no leaks

## Still Having Issues?

### If it still stops:
1. Check the latest log file in `logs/`
2. Look for the last successful operation
3. Check if tokens are actually exhausted or if there's another error
4. Consider reducing to 2 workers: `MAX_WORKERS = 2`

### Additional Debug Steps:
```python
# Add this to see thread activity (already in watchdog)
# The watchdog checks every 2 minutes for progress
# If no progress for 3 checks (6 min), it will alert you
```

## Hardware Upgrade Recommendations

For faster scraping:
- **4-core/8-thread CPU**: Use `MAX_WORKERS = 8`
- **6-core/12-thread CPU**: Use `MAX_WORKERS = 12`
- **Rule of thumb**: `MAX_WORKERS = number_of_threads` or slightly higher if you have many tokens

## Summary

The deadlock fix ensures:
1. âœ… Thread-safe rate limit handling
2. âœ… No blocking on network operations
3. âœ… Optimal worker count for your hardware
4. âœ… Graceful error handling
5. âœ… Single sleep coordinator

Your scraper should now complete without hanging! ğŸš€
